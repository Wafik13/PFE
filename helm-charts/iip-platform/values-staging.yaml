# Staging Environment Values for IIP Platform
# Pre-production testing environment with production-like configuration

global:
  environment: staging
  domain: staging-iip.company.com
  imageRegistry: registry.gitlab.company.com/iip/platform
  imagePullPolicy: Always  # Always pull latest for testing
  storageClass: iip-ssd
  
# Staging resource allocation (scaled down from production)
scada:
  replicaCount: 2
  image:
    tag: "latest"  # Use latest for staging testing
  resources:
    requests:
      cpu: 300m
      memory: 512Mi
    limits:
      cpu: 1
      memory: 1Gi
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
  env:
    LOG_LEVEL: DEBUG
    ENABLE_DEBUG_ENDPOINTS: "true"
    CONNECTION_POOL_SIZE: 10
    MAX_CONCURRENT_REQUESTS: 50
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    initialDelaySeconds: 15
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3

analytics:
  replicaCount: 2
  image:
    tag: "latest"
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2
      memory: 2Gi
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 8
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
  env:
    LOG_LEVEL: DEBUG
    BATCH_SIZE: 500
    WORKER_THREADS: 2
    CACHE_TTL: 300

mlInference:
  replicaCount: 2
  image:
    tag: "latest"
  resources:
    requests:
      cpu: 500m
      memory: 2Gi
      nvidia.com/gpu: 1
    limits:
      cpu: 2
      memory: 4Gi
      nvidia.com/gpu: 1
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 6
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: 70
    targetGPUUtilizationPercentage: 80
  env:
    LOG_LEVEL: DEBUG
    MODEL_CACHE_SIZE: 3
    INFERENCE_TIMEOUT: 30
    BATCH_INFERENCE: "true"
    MAX_BATCH_SIZE: 16

frontend:
  replicaCount: 2
  image:
    tag: "latest"
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 70
  env:
    NODE_ENV: staging
    API_BASE_URL: https://staging-iip.company.com/api
    WEBSOCKET_URL: wss://staging-iip.company.com/ws
    ENABLE_DEBUG: "true"
    CACHE_STATIC_ASSETS: "false"

# Staging infrastructure components
postgresql:
  auth:
    postgresPassword: "${POSTGRES_PASSWORD}"
    database: iip_staging
  architecture: replication
  primary:
    persistence:
      enabled: true
      size: 100Gi
      storageClass: iip-ssd
    resources:
      requests:
        cpu: 1
        memory: 2Gi
      limits:
        cpu: 2
        memory: 4Gi
    configuration: |
      max_connections = 100
      shared_buffers = 1GB
      effective_cache_size = 3GB
      maintenance_work_mem = 256MB
      checkpoint_completion_target = 0.9
      wal_buffers = 16MB
      default_statistics_target = 100
      random_page_cost = 1.1
      effective_io_concurrency = 200
      work_mem = 4MB
      min_wal_size = 512MB
      max_wal_size = 2GB
  readReplicas:
    replicaCount: 1
    persistence:
      enabled: true
      size: 100Gi
      storageClass: iip-ssd
    resources:
      requests:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 1
        memory: 2Gi
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true

redis:
  auth:
    enabled: true
    password: "${REDIS_PASSWORD}"
  architecture: replication
  master:
    persistence:
      enabled: true
      size: 10Gi
      storageClass: iip-ssd
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi
    configuration: |
      maxmemory-policy allkeys-lru
      timeout 300
      tcp-keepalive 300
      maxclients 1000
  replica:
    replicaCount: 1
    persistence:
      enabled: true
      size: 10Gi
      storageClass: iip-ssd
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 300m
        memory: 512Mi
  sentinel:
    enabled: true
    masterSet: mymaster
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true

rabbitmq:
  auth:
    username: "${RABBITMQ_USERNAME}"
    password: "${RABBITMQ_PASSWORD}"
  clustering:
    enabled: true
    replicaCount: 2
  persistence:
    enabled: true
    size: 20Gi
    storageClass: iip-ssd
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1Gi
  configuration: |
    vm_memory_high_watermark.relative = 0.6
    disk_free_limit.relative = 1.0
    cluster_partition_handling = autoheal
    queue_master_locator = min-masters
    loopback_users.guest = false
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true

minio:
  auth:
    rootUser: "${MINIO_ROOT_USER}"
    rootPassword: "${MINIO_ROOT_PASSWORD}"
  mode: distributed
  replicas: 2
  persistence:
    enabled: true
    size: 200Gi
    storageClass: iip-ssd
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 1
      memory: 2Gi
  configuration: |
    MINIO_CACHE_DRIVES="/tmp/cache1"
    MINIO_CACHE_EXCLUDE="*.pdf,*.doc"
    MINIO_CACHE_QUOTA=80
    MINIO_CACHE_AFTER=3
    MINIO_CACHE_WATERMARK_LOW=70
    MINIO_CACHE_WATERMARK_HIGH=90
  metrics:
    serviceMonitor:
      enabled: true

influxdb:
  auth:
    admin:
      username: "${INFLUXDB_ADMIN_USER}"
      password: "${INFLUXDB_ADMIN_PASSWORD}"
      token: "${INFLUXDB_ADMIN_TOKEN}"
  persistence:
    enabled: true
    size: 200Gi
    storageClass: iip-ssd
  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 2
      memory: 4Gi
  configuration: |
    [http]
      max-concurrent-queries = 50
      max-select-point = 0
      max-select-series = 0
      max-select-buckets = 0
    [data]
      cache-max-memory-size = "1g"
      cache-snapshot-memory-size = "256m"
      cache-snapshot-write-cold-duration = "10m"
      compact-full-write-cold-duration = "4h"
      max-series-per-database = 500000
      max-values-per-tag = 50000
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true

# Staging API Gateway configuration
kong:
  env:
    database: postgres
    pg_host: postgresql.iip-infrastructure.svc.cluster.local
    pg_port: 5432
    pg_database: kong
    pg_user: kong
    pg_password: "${KONG_PG_PASSWORD}"
    log_level: debug
    nginx_worker_processes: auto
    nginx_worker_connections: 2048
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 1
      memory: 1Gi
  replicaCount: 2
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 70
  plugins:
    - name: rate-limiting
      config:
        minute: 500
        hour: 5000
    - name: cors
      config:
        origins: ["https://staging-iip.company.com"]
        methods: ["GET", "POST", "PUT", "DELETE"]
        headers: ["Accept", "Authorization", "Content-Type"]
        credentials: true
    - name: jwt
      config:
        secret_is_base64: false
        claims_to_verify: ["exp", "iss", "aud"]
    - name: prometheus
      config:
        per_consumer: true

# Staging Service Mesh configuration
istio:
  pilot:
    env:
      PILOT_TRACE_SAMPLING: 10.0  # 10% sampling in staging
      PILOT_ENABLE_WORKLOAD_ENTRY_AUTOREGISTRATION: true
    resources:
      requests:
        cpu: 200m
        memory: 1Gi
      limits:
        cpu: 500m
        memory: 2Gi
  proxy:
    resources:
      requests:
        cpu: 50m
        memory: 64Mi
      limits:
        cpu: 200m
        memory: 256Mi
  gateway:
    replicaCount: 2
    autoscaling:
      enabled: true
      minReplicas: 2
      maxReplicas: 5

# Staging MLOps components
feast:
  replicaCount: 1
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 1
      memory: 1Gi
  env:
    LOG_LEVEL: DEBUG
    FEAST_USAGE_ENABLED: "true"
    FEAST_TELEMETRY_ENABLED: "false"
  persistence:
    enabled: true
    size: 50Gi
    storageClass: iip-ssd

mlflow:
  replicaCount: 1
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 1
      memory: 1Gi
  env:
    MLFLOW_TRACKING_URI: http://mlflow.iip-mlops.svc.cluster.local:5000
    MLFLOW_S3_ENDPOINT_URL: http://minio.iip-infrastructure.svc.cluster.local:9000
    MLFLOW_ARTIFACT_ROOT: s3://mlflow-artifacts
  persistence:
    enabled: true
    size: 100Gi
    storageClass: iip-ssd

argoWorkflows:
  controller:
    replicas: 1
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi
    persistence:
      enabled: true
      size: 20Gi
      storageClass: iip-ssd
  server:
    replicas: 1
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 300m
        memory: 512Mi
    authMode: server

kserve:
  controller:
    replicas: 1
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi
  webhook:
    replicas: 1
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 300m
        memory: 512Mi

# Staging monitoring stack
prometheus:
  server:
    retention: "7d"
    retentionSize: "50GB"
    persistentVolume:
      size: 100Gi
      storageClass: iip-ssd
    resources:
      requests:
        cpu: 500m
        memory: 2Gi
      limits:
        cpu: 1
        memory: 4Gi
    replicaCount: 1
    configuration: |
      global:
        scrape_interval: 15s
        evaluation_interval: 15s
        external_labels:
          cluster: 'iip-staging'
          environment: 'staging'
      rule_files:
        - "/etc/prometheus/rules/*.yml"
      scrape_configs:
        - job_name: 'kubernetes-pods'
          kubernetes_sd_configs:
            - role: pod
          relabel_configs:
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
              action: keep
              regex: true
  alertmanager:
    enabled: true
    replicaCount: 1
    persistence:
      enabled: true
      size: 5Gi
      storageClass: iip-ssd
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 300m
        memory: 512Mi
    configuration:
      global:
        smtp_smarthost: 'smtp.company.com:587'
        smtp_from: 'staging-alerts@company.com'
      route:
        group_by: ['alertname', 'cluster', 'service']
        group_wait: 10s
        group_interval: 10s
        repeat_interval: 1h
        receiver: 'web.hook'
      receivers:
        - name: 'web.hook'
          webhook_configs:
            - url: 'http://alertmanager-webhook:5000/'

grafana:
  persistence:
    enabled: true
    size: 10Gi
    storageClass: iip-ssd
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 300m
      memory: 512Mi
  replicaCount: 1
  adminPassword: "${GRAFANA_ADMIN_PASSWORD}"
  env:
    GF_LOG_LEVEL: debug
    GF_USERS_ALLOW_SIGN_UP: "false"
    GF_AUTH_ANONYMOUS_ENABLED: "false"
    GF_SECURITY_ADMIN_PASSWORD: "${GRAFANA_ADMIN_PASSWORD}"
    GF_INSTALL_PLUGINS: "grafana-piechart-panel,grafana-worldmap-panel"
  datasources:
    - name: Prometheus
      type: prometheus
      url: http://prometheus-server:80
      access: proxy
      isDefault: true
    - name: InfluxDB
      type: influxdb
      url: http://influxdb:8086
      database: iip_staging

# Staging security settings
security:
  jwt:
    secret: "${JWT_SECRET}"
    issuer: iip-staging
    audience: iip-staging-users
    expirationTime: 24h  # Longer expiration for testing
    algorithm: RS256
  cors:
    allowedOrigins:
      - "https://staging-iip.company.com"
      - "http://localhost:3000"  # Allow local development
    allowedMethods:
      - GET
      - POST
      - PUT
      - DELETE
      - OPTIONS
    allowCredentials: true
    maxAge: 86400
  networkPolicies:
    enabled: true
    defaultDeny: false  # More permissive for testing
  podSecurityPolicy:
    enabled: true
  rbac:
    enabled: true
    strictMode: false  # Less strict for testing

# Staging ingress configuration
ingress:
  enabled: true
  className: nginx
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-staging"
    nginx.ingress.kubernetes.io/rate-limit: "200"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
  hosts:
    - host: staging-iip.company.com
      paths:
        - path: /
          pathType: Prefix
          service:
            name: frontend
            port: 80
        - path: /api
          pathType: Prefix
          service:
            name: kong-proxy
            port: 80
  tls:
    - secretName: iip-staging-tls
      hosts:
        - staging-iip.company.com

# Staging persistent volumes
persistentVolumes:
  storageClass: iip-ssd
  accessMode: ReadWriteOnce
  reclaimPolicy: Delete  # Delete for staging to save costs
  backupPolicy: weekly

# Staging node affinity (less strict)
nodeAffinity:
  enabled: true
  requiredDuringScheduling: false
  preferredDuringScheduling: true

# Pod disruption budgets (less strict)
podDisruptionBudget:
  enabled: true
  minAvailable: 1

# Staging-specific features
staging:
  testingEnabled: true
  debugMode: true
  performanceTesting: true
  loadTesting: true
  integrationTesting: true
  e2eTesting: true
  mockExternalServices: true
  dataSeeding: true

# External services (staging endpoints)
externalServices:
  mqtt:
    broker: mqtts://staging-mqtt-broker:8883
    username: "${MQTT_USERNAME}"
    password: "${MQTT_PASSWORD}"
    tls: true
    caFile: /etc/ssl/certs/mqtt-ca.crt
  opcua:
    endpoint: opc.tcp://staging-opcua-server:4840
    username: "${OPCUA_USERNAME}"
    password: "${OPCUA_PASSWORD}"
    security: SignAndEncrypt
    certificate: /etc/ssl/certs/opcua-client.crt
    privateKey: /etc/ssl/private/opcua-client.key
  weather:
    apiKey: "${WEATHER_API_KEY}"
    endpoint: https://api.openweathermap.org/data/2.5
    timeout: 30s
    retries: 3

# Backup configuration (reduced frequency)
backup:
  enabled: true
  schedule: "0 3 * * 0"  # Weekly on Sunday at 3 AM
  retention: 7  # Keep 7 days
  destinations:
    - s3://iip-backups-staging/
  encryption: true
  compression: true

# Testing configuration
testing:
  enabled: true
  loadTesting:
    enabled: true
    duration: 10m
    virtualUsers: 100
    rampUpTime: 2m
  performanceTesting:
    enabled: true
    thresholds:
      responseTime: 500ms
      throughput: 1000rps
      errorRate: 1%
  integrationTesting:
    enabled: true
    testSuites:
      - api
      - database
      - messaging
      - ml-inference
  e2eTesting:
    enabled: true
    browsers:
      - chrome
      - firefox
    headless: true

# Data seeding for testing
dataSeeding:
  enabled: true
  datasets:
    - name: sample-scada-data
      size: 1000
      timeRange: 24h
    - name: sample-sensor-data
      size: 10000
      timeRange: 7d
    - name: sample-ml-models
      count: 5
      types: ["classification", "regression", "anomaly-detection"]

# Mock services for testing
mockServices:
  enabled: true
  services:
    - name: mock-weather-api
      port: 8080
      responses:
        - endpoint: /current
          method: GET
          response: {"temperature": 25, "humidity": 60}
    - name: mock-equipment-api
      port: 8081
      responses:
        - endpoint: /status
          method: GET
          response: {"status": "operational", "efficiency": 95}

# Feature flags for staging
featureFlags:
  newDashboard: true
  advancedAnalytics: true
  experimentalMLModels: true
  betaFeatures: true
  debugTools: true